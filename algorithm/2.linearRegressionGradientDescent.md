# Linear Regression with Gradient Descent

Here I will introduce the gradient descent algorithm and its application to solve linear regression problems with OLS loss function, then
I will extend it to some other loss functions such as L1-norm loss function.

## Gradient Descent

As previously show in ![linear regression](https://github.com/chenxingwei/machine_learning_from_scratch/blob/master/algorithm/1.linearRegression.md), we can solve linear regression  with derivatives. But many complex functions do not have an analytical solution, or they are hard and complex to solve through a mathematics way. Then comes for Gradient Descent, which can be used to solve minimize or maximize problems.

### How gradient descent works?

We have previously in the linear regression part shown that gradient is the derivatives of a vector or matrix. Here we will go over how gradient descent works in low-dimensional examples. 

If we have a function like ![equation](http://latex.codecogs.com/gif.latex?y=x^2) with its curve as figure below. 

![](https://github.com/chenxingwei/machine_learning_from_scratch/blob/master/images/lr_001.png)

We have two points on the curve, one on the left and the other on the right. We firstly take a look at the point A, with a coordinate ![equation](http://latex.codecogs.com/gif.latex?(-2,4)), with very basic math knowledge we will get the tangent line at A is ![equation](http://latex.codecogs.com/gif.latex?y=-4x-4) as indicated by the red line. And the point B with coordinate ![equation](http://latex.codecogs.com/gif.latex?(1,1)) on the right, similarly we have its tangent line with function ![equation](http://latex.codecogs.com/gif.latex?X=2x-1) as indicated by the blue line.

The derivitives (gradient) at point A keeps the same for the curve and the tangent line, then we have derivative (gradient, maybe also can be called slope) at A and B are ![equation](http://latex.codecogs.com/gif.latex?-4) and ![equation](http://latex.codecogs.com/gif.latex?2), respectively.

The gradient have orientations, in the example above, the orientation of gradient at A is tend to negative infinity and the orientation of gradient at B is tend to posive infinity. How can we get to the minimum value in the above example? It is obviously shown that we should tend positive at point A, in the opposite orientation of the gradient at point A. Similarly, we should tend negative at point B which is also in the opposite orientation of the gradient at point B.

It is similar at high-dimensional parameter spaces.

### Gradient descent for OLS linear regression

Updating paramters at the negative orientation of the gradient is gradient descent methods. For example, if the loss function is ![equation](http://latex.codecogs.com/gif.latex?J(\theta)), then formula below is used for the gradient descent:

![equation](http://latex.codecogs.com/gif.latex?\theta_{j}=\theta_{j}-\alpha\frac{\partial}{\partial{\theta_j}}J(\theta))

In the formula, ![equation](http://latex.codecogs.com/gif.latex?\alpha) is the learning rate, indicating how long should we update the parameters through the negative gradient direction.

We have previously stated the OLS loss function in ![linear regression](https://github.com/chenxingwei/machine_learning_from_scratch/blob/master/algorithm/1.linearRegression.md), following is the formula:

![equation](http://latex.codecogs.com/gif.latex?J(\theta)=\frac{1}{2}(X\theta-\overrightarrow{y})^T(X\theta-\overrightarrow{y}))

We will first introduce how to do this on only one input sample, then the loss on sample ![equation](http://latex.codecogs.com/gif.latex?x_i) will be 

![equation](http://latex.codecogs.com/gif.latex?J(\theta;x_i)=\frac{1}{2}(x_i\theta-y_i)^2=\frac{1}{2}(\sum_{j=1}^{m+1}x_{ij}\theta_j-y_i)^2)

Then the derivative of the loss function for one parameter ![equation](http://latex.codecogs.com/gif.latex?\theta_j) can be calculated as:

![equation](http://latex.codecogs.com/gif.latex?\frac{\partial{J(\theta;x_i)}}{\partial{\theta_j}}=(x_i\theta-y_i)x_{ij})

Then we can vectorize it for all parameters as:

![equation](http://latex.codecogs.com/gif.latex?\nabla_{\theta}J(\theta;x_i)=(x_i\theta-y_i)x_{i})

Update rule above is only for one sample, here then for all the samples we will have:

![equation](http://latex.codecogs.com/gif.latex?\nabla_{\theta}J(\theta)=\frac{1}{n}\sum_{i=1}^{n}(x_i\theta-y_i)x_{i})

It is the same to skip the sample size, which only affect the choose of learning rate:

![equation](http://latex.codecogs.com/gif.latex?\nabla_{\theta}J(\theta)=\sum_{i=1}^{n}(x_i\theta-y_i)x_{i})

Then by setting learning rate ![equation](http://latex.codecogs.com/gif.latex?\alpha), we could could be running on the linear regression using gradient descent.

### Python solution of linear regression using gradient descent

We will have two extra functions, one for calculating the loss, and one for calculate the gradient. Loss is used to eary stop the iteration and gradient is used for updating parameters.

```python
import os, glob, math
import numpy as np
import random

class linear_regression_GD:
  """
  linear regression with OLS loss function, and solving by gradient descent methods.
  """
  def __init__(self):
    self.rmse = None
    pass
  
  def train(self, X, y, learning_rate=0.001, epoch=3000, tol=1e-4, methods="OLS"):
    """
    If data not the required format, this function not works
    @param X, independent variable, example: X = np.array([[1,2,],[1,3,],[1,4], ...])
    @param y, dependent variable, example y = np.array([[1],[2],[3],[4],...])
    Both X and y should be an array.
    @param learning_rate, step size for gradient descent
    @param epoch, times the training process go over the whole datasets
    @param tol, the stop critera, when loss function did not optimize more than tol for 10 times, stop training
    @param methods, the loss function, OLS stands for ordinary least square loss function
    @return, this function will return weight vector w and bias parameter b
    """
    n = len(X)
    self.n = n
    m = len(X[0])
    if len(y) != n:
      print "Error, the input X, y should be the same length, while you have len(X)=%d and len(y)=%d"%(n, len(y))
    
    # following codes reformat the input, this function only for simple linear regression
    X = np.array(X)
    y = np.array(y)
    
    if len(y.shape) != 2:
      y = y.reshape(n,1)
    
    # add a 1 column for the bias variable
    X = np.column_stack((X, np.ones(n)))
    self.X = X
    self.y = y
    
    # get the parameter w and b, first initize
    theta = np.random.randn(m+1)
    num = 0
    loss1 = self.getLoss(theta)
    for i in xrange(epoch):
      theta -= self.getGradient(theta, methods)
      loss2 = self.getLoss(theta)
      if abs(loss2-loss1) < tol:
        num += 1
      else:
        num = 0
      loss1 = loss2
      if num >= 10:
        break
    self.w = theta[:-1]
    self.b = theta[-1]
    return theta
    
  def getLoss(self, theta, method="OLS"):
    """
    @param theta, the parameters for the linear model
    @return the loss of this model with given parameters
    """
    if methods == "OLS":
      return np.sum(np.square(self.X.dot(theta) - self.y)) / self.n
    else:
      print 'Error, methods now can only be "OLS"'
  
  def getGradient(self, theta):
    """
    Get the gradient of the loss function using parameter theta
    """
    delta = np.sum(self.X.T * self.X.dot(theta)-self.y, axis=1)
    return delta
  
  def predict(self, X, y=None):
    """
    @param X, independent variable.
    Example: X = np.array([[1,2,],[1,3,],[1,4], ...])
    @param y, dependent variable, example y = np.array([[1],[2],[3],[4],...])
    @return, return the predicted dependent variables for input X, or if y is specified, also calculate the RMSE (root mean square error)
    """
    n = len(X)
    X = np.array(X)
    y_pred = X.dot(self.w) + self.b
    self.y_pred = y_pred
    if y != None:
      if n != len(y):
        print "Error, the input X, y should be the same length, while you have len(X)=%d and len(y)=%d"%(n, len(y))
      y = np.array(y)
      y_pred = y_pred.reshape(n)
      if len(y.shape) != 1:
        y = y.reshape(n)
      self.rmse = np.sqrt(np.sum(np.square(y-y_pred))) / n
    return self.y_pred
  

```



