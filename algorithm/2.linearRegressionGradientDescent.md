# Linear Regression with Gradient Descent

Here I will introduce the gradient descent algorithm and its application to solve linear regression problems with OLS loss function, then
I will extend it to some other loss functions such as L1-norm loss function.

## Gradient Descent

As previously show in ![linear regression](https://github.com/chenxingwei/machine_learning_from_scratch/blob/master/algorithm/1.linearRegression.md), we can solve linear regression  with derivatives. But many complex functions do not have an analytical solution, or they are hard and complex to solve through a mathematics way. Then comes for Gradient Descent, which can be used to solve minimize or maximize problems.

### How gradient descent works?

We have previously in the linear regression part shown that gradient is the derivatives of a vector or matrix. Here we will go over how gradient descent works in low-dimensional examples. 

If we have a function like ![equation](http://latex.codecogs.com/gif.latex?y=x^2) with its curve as figure below. 

![](https://github.com/chenxingwei/machine_learning_from_scratch/blob/master/images/lr_001.png)

We have two points on the curve, one on the left and the other on the right. We firstly take a look at the point A, with a coordinate ![equation](http://latex.codecogs.com/gif.latex?(-2,4)), with very basic math knowledge we will get the tangent line at A is ![equation](http://latex.codecogs.com/gif.latex?y=-4x-4) as indicated by the red line. And the point B with coordinate ![equation](http://latex.codecogs.com/gif.latex?(1,1)) on the right, similarly we have its tangent line with function ![equation](http://latex.codecogs.com/gif.latex?X=2x-1) as indicated by the blue line.

The derivitives (gradient) at point A keeps the same for the curve and the tangent line, then we have derivative (gradient, maybe also can be called slope) at A and B are ![equation](http://latex.codecogs.com/gif.latex?-4) and ![equation](http://latex.codecogs.com/gif.latex?2), respectively.

The gradient have orientations, in the example above, the orientation of gradient at A is tend to negative infinity and the orientation of gradient at B is tend to posive infinity. How can we get to the minimum value in the above example? It is obviously shown that we should tend positive at point A, in the opposite orientation of the gradient at point A. Similarly, we should tend negative at point B which is also in the opposite orientation of the gradient at point B.

It is similar at high-dimensional parameter spaces.

### Gradient descent for OLS linear regression

Updating paramters at the negative orientation of the gradient is gradient descent methods. For example, if the loss function is ![equation](http://latex.codecogs.com/gif.latex?J(\theta)), then formula below is used for the gradient descent:

![equation](http://latex.codecogs.com/gif.latex?\theta_{j}=\theta_{j}-\alpha\frac{\partial}{\partial{\theta_j}}J(\theta))

In the formula, ![equation](http://latex.codecogs.com/gif.latex?\alpha) is the learning rate, indicating how long should we update the parameters through the negative gradient direction.

We have previously stated the OLS loss function in ![linear regression](https://github.com/chenxingwei/machine_learning_from_scratch/blob/master/algorithm/1.linearRegression.md), following is the formula:

![equation](http://latex.codecogs.com/gif.latex?J(\theta)=\frac{1}{2}(X\theta-\overrightarrow{y})^T(X\theta-\overrightarrow{y}))

We will first introduce how to do this on only one input sample, then the loss on sample ![equation](http://latex.codecogs.com/gif.latex?x_i) will be 

![equation](http://latex.codecogs.com/gif.latex?J(\theta;x_i)=\frac{1}{2}(x_i\theta-y_i)^2=\frac{1}{2}(\sum_{j=1}^{m+1}x_{ij}\theta_j-y_i)^2)

Then the derivative of the loss function for one parameter ![equation](http://latex.codecogs.com/gif.latex?\theta_j) can be calculated as:

![equation](http://latex.codecogs.com/gif.latex?\frac{\partial{J(\theta;x_i)}}{\partial{\theta_j}}=(x_i\theta-y_i)x_{ij})

Then we can vectorize it for all parameters as:

![equation](http://latex.codecogs.com/gif.latex?\nabla_{\theta}J(\theta;x_i)=(x_i\theta-y_i)x_{i})

Update rule above is only for one sample, here then for all the samples we will have:

![equation](http://latex.codecogs.com/gif.latex?\nabla_{\theta}J(\theta)=\frac{1}{n}\sum_{i=1}^{n}(x_i\theta-y_i)x_{i})

It is the same to skip the sample size, which only affect the choose of learning rate:

![equation](http://latex.codecogs.com/gif.latex?\nabla_{\theta}J(\theta)=\sum_{i=1}^{n}(x_i\theta-y_i)x_{i})

Then by setting learning rate ![equation](http://latex.codecogs.com/gif.latex?\alpha), we could could be running on the linear regression using gradient descent.

### Python solution of linear regression using gradient descent

We will have two extra functions, one for calculating the loss, and one for calculate the gradient. Loss is used to eary stop the iteration and gradient is used for updating parameters.

```python
import os, glob, math
import numpy as np
import random

class linear_regression_GD:
  """
  linear regression with OLS loss function, and solving by gradient descent methods.
  """
  def __init__(self):
    self.rmse = None
    pass
  
  def train(self, X, y, learning_rate=0.001, epoch=30000, tol=1e-4, methods="OLS"):
    """
    If data not the required format, this function not works
    @param X, independent variable, example: X = np.array([[1,2,],[1,3,],[1,4], ...])
    @param y, dependent variable, example y = np.array([[1],[2],[3],[4],...])
    Both X and y should be an array.
    @param learning_rate, step size for gradient descent
    @param epoch, times the training process go over the whole datasets
    @param tol, the stop critera, when loss function did not optimize more than tol for 10 times, stop training
    @param methods, the loss function, OLS stands for ordinary least square loss function
    @return, this function will return weight vector w and bias parameter b
    """
    n = len(X)
    self.n = n
    m = len(X[0])
    if len(y) != n:
      print "Error, the input X, y should be the same length, while you have len(X)=%d and len(y)=%d"%(n, len(y))
    
    # following codes reformat the input, this function only for simple linear regression
    X = np.array(X)
    y = np.array(y)
    
    if len(y.shape) != 1:
      y = y.reshape(n)
    
    # add a 1 column for the bias variable
    X = np.column_stack((X, np.ones(n)))
    self.X = X
    self.y = y
    
    # get the parameter w and b, first initize
    theta = np.random.randn(m+1)
    num = 0
    loss1 = self.getLoss(theta)
    for i in xrange(epoch):
      theta -= learning_rate * self.getGradient(theta)
      loss2 = self.getLoss(theta, methods)
      if abs(loss2-loss1) < tol:
        num += 1
      else:
        num = 0
      loss1 = loss2
      self.epoch = i
      #if num >= 10:
      #  break
    self.w = theta[:-1]
    self.b = theta[-1]
    return theta
    
  def getLoss(self, theta, methods="OLS"):
    """
    @param theta, the parameters for the linear model
    @return the loss of this model with given parameters
    """
    if methods == "OLS":
      # divide self.n first to avoid float overflow to some extent.
      return np.sum(np.square((self.X.dot(theta) - self.y)/self.n) * self.n)
    else:
      print 'Error, methods now can only be "OLS"'
  
  def getGradient(self, theta):
    """
    Get the gradient of the loss function using parameter theta
    """
    delta = np.sum(self.X.T * (self.X.dot(theta)-self.y), axis=1)
    return delta
  
  def predict(self, X, y=None):
    """
    @param X, independent variable.
    Example: X = np.array([[1,2,],[1,3,],[1,4], ...])
    @param y, dependent variable, example y = np.array([[1],[2],[3],[4],...])
    @return, return the predicted dependent variables for input X, or if y is specified, also calculate the RMSE (root mean square error)
    """
    n = len(X)
    X = np.array(X)
    y_pred = X.dot(self.w) + self.b
    self.y_pred = y_pred
    if y != None:
      if n != len(y):
        print "Error, the input X, y should be the same length, while you have len(X)=%d and len(y)=%d"%(n, len(y))
      y = np.array(y)
      y_pred = y_pred.reshape(n)
      if len(y.shape) != 1:
        y = y.reshape(n)
      self.rmse = np.sqrt(np.sum(np.square(y-y_pred))) / n
    return self.y_pred
  
```

Codes can be also fetched at ![linear regression with gradient descent](https://github.com/chenxingwei/machine_learning_from_scratch/blob/master/codes/linear_regression_gd.py).

### Advantages and disadvantages of gradient descent

It is easy to understand how gradient descent works, and it is also easy to implementation. It will be very difficult to come out the analytical solution when we have more parameters or the loss function is much complex. 

However for linear regression, gradient descent will not always get to the optimized paramaters because of different setting of learning rate and epoches to train. And it takes much longer for gradient descent to reach some parameters that could train the input data "well". And maybe the gradient descent will "never" get to the global minimum.

## Gradient descent to solve linear regression with mean absolute error (MAE) loss function

Except for the Ordinary Least Square (OLS) loss function, we could also construct the mean absolute error (MAE) as the loss function, its formula can be expressed as:

![equation](http://latex.codecogs.com/gif.latex?L=\frac{1}{n}\sum_{i=1}^{n}|x_i\theta-y_i|)

Linear regression using MAE loss function is hard to get get the analytical solution. But it is extremely easy using gradient descent alogrithm, much easier than previous shown OLS loss function.

Similarly, we start with the loss function for one single sample:

![equation](http://latex.codecogs.com/gif.latex?J(\theta;x_i)=|x_i\theta-y_i|=|\sum_{k=1}^{n}x_{ik}\theta_k-y_i|)

Then the partial derivative for the loss function isï¼š

![equation](http://latex.codecogs.com/gif.latex?\frac{\partial{J(\theta;x_i)}}{\partial{\theta_j}}=x_{ij},\sum_{k=1}^{n}x_{ik}\theta_k-y_i\ge0)

![equation](http://latex.codecogs.com/gif.latex?\frac{\partial{J(\theta;x_i)}}{\partial{\theta_j}}=-x_{ij},\sum_{k=1}^{n}x_{ik}\theta_k-y_i<0)

Then it is very straightforward to generate the gradient for one single sample:

![equation](http://latex.codecogs.com/gif.latex?\nabla_{\theta}J(\theta;x_i)=x_{i},\sum_{k=1}^{n}x_{ik}\theta_k-y_i\ge0)

![equation](http://latex.codecogs.com/gif.latex?\nabla_{\theta}J(\theta;x_i)=-x_{i},\sum_{k=1}^{n}x_{ik}\theta_k-y_i<0)

The gradient for one sample is the data of this sample itself, multiple 1 or -1 according to it is modelled by the current parameters to be larger or smaller than its real value.

And it is very easy to vectorize across some more samples. Then I will give the codes for MAE loss function.

### Python solution for linear regression using MAE as loss function

Here I will used the same class as the linear regression using OLS as loss function above. But implement a new gradient descent update schedule.

```python
import os, glob, math
import numpy as np
import random

class linear_regression_GD:
  """
  linear regression with OLS loss function, and solving by gradient descent methods.
  """
  def __init__(self):
    self.rmse = None
    pass
  
  def train(self, X, y, learning_rate=0.001, epoch=30000, tol=1e-4, methods="OLS"):
    """
    If data not the required format, this function not works
    @param X, independent variable, example: X = np.array([[1,2,],[1,3,],[1,4], ...])
    @param y, dependent variable, example y = np.array([[1],[2],[3],[4],...])
    Both X and y should be an array.
    @param learning_rate, step size for gradient descent
    @param epoch, times the training process go over the whole datasets
    @param tol, the stop critera, when loss function did not optimize more than tol for 10 times, stop training
    @param methods, the loss function, OLS stands for ordinary least square loss function
    @return, this function will return weight vector w and bias parameter b
    """
    n = len(X)
    self.n = n
    m = len(X[0])
    if len(y) != n:
      print "Error, the input X, y should be the same length, while you have len(X)=%d and len(y)=%d"%(n, len(y))
    
    # following codes reformat the input, this function only for simple linear regression
    X = np.array(X)
    y = np.array(y)
    
    if len(y.shape) != 1:
      y = y.reshape(n)
    
    # add a 1 column for the bias variable
    X = np.column_stack((X, np.ones(n)))
    self.X = X
    self.y = y
    
    # get the parameter w and b, first initize
    theta = np.random.randn(m+1)
    num = 0
    for i in xrange(epoch):
      theta -= learning_rate * self.getGradient(theta, methods)
      self.epoch = i
    self.w = theta[:-1]
    self.b = theta[-1]
    return theta
  
  def getGradient(self, theta, methods="OLS"):
    """
    Get the gradient of the loss function using parameter theta
    """
    methods_from = ["OLS", "MAE"]
    if methods == "OLS":
      delta = np.sum(self.X.T * (self.X.dot(theta)-self.y), axis=1)
    elif methods == 'MAE':
      judge = np.sign(self.X.dot(theta) - self.y)
      delta = np.sum(self.X * judge.reshape(self.n,1) / self.n, axis=0)
    else:
      print "Error, the methods parameter can only be ", methods_from
    return delta
  
  def predict(self, X, y=None):
    """
    @param X, independent variable.
    Example: X = np.array([[1,2,],[1,3,],[1,4], ...])
    @param y, dependent variable, example y = np.array([[1],[2],[3],[4],...])
    @return, return the predicted dependent variables for input X, or if y is specified, also calculate the RMSE (root mean square error)
    """
    n = len(X)
    X = np.array(X)
    y_pred = X.dot(self.w) + self.b
    self.y_pred = y_pred
    if y != None:
      if n != len(y):
        print "Error, the input X, y should be the same length, while you have len(X)=%d and len(y)=%d"%(n, len(y))
      y = np.array(y)
      y_pred = y_pred.reshape(n)
      if len(y.shape) != 1:
        y = y.reshape(n)
      self.rmse = np.sqrt(np.sum(np.square(y-y_pred))) / n
    return self.y_pred

  
```

Codes can also be fetched at [Linear regression with gradient descent](https://github.com/chenxingwei/machine_learning_from_scratch/blob/master/codes/linear_regression_gd.py).


Now, we have been familar with gradient descent algorithm and how it can be applied to optimization problems. Then we will further introduce gradient descent to solove logistic regression, and regularization.



